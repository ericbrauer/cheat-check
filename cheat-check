#!/usr/bin/env python3

from re import sub, match, findall
import sys, os, glob, fnmatch
# import pycode_similar as pysim
import argparse
import ast, traceback
from difflib import SequenceMatcher as sm
from keyword import iskeyword
import display as d

'''
November 2021: trying to improve this. pycode_similar not giving good results. Attempt is: difflib.Sequencematcher
November 2023: more TODOs
done ability to run a diff directly on both files
    create a .config file where executable is stored
    finally do packaging.
DONE migrate viewers into a different module
done lol, percentage goes up depending on which file is first. see ldevassy @ 58.9% vs sjohn @ 44.3%
TODO revisit the idea of improved diff checking by stripping out all non-keywords
done use a class rather than frozenset/tuple/whatever the fuck it is here: a dictionary of tuple + percentage! Oy Vey
TODO add more comments
TODO performance! multithreading?
'''

class FileReport:

    class Result:
        "stores individual result"
        def __init__(self, f1, pcnt, f2):
            self.f1 = f1
            self.pcnt = pcnt
            self.f2 = f2

        def tup(self):
            return (self.f1, self.pcnt, self.f2)

        def __repr__(self):
            return f'{self.f1},{self.pcnt},{self.f2}'

        def __lt__(self, other):
            return self.pcnt < other.pcnt
    

    def __init__(self, filename):
        self.filename = filename  # the complete filepath of the file
        self.data = self.filter_comments_from_py(open(filename).read())
        self.similars = []  # list of Results
        # k: filepath v: percent

    def __repr__(self):
        return self.filename

    def add_result(self, filename, pcnt):
        r = self.Result(self.filename, pcnt, filename)
        self.similars.append(r)
    
    def filter_comments_from_py(self, raw: str):
        "given a file object, remove docstrings and inline comments"
        docreg = r"[\'\"]{3}(.|\n)+?[\'\"]{3}"  # filter between """ or '''
        comreg = r"#(\w|\s)*\n"  # filter # to end of line
        # raw = file_obj.read()
        raw = sub(docreg, '', raw)
        raw = sub(comreg, '\n', raw) 
        return raw

    def byte_compare(self, d2, threshold):
        "if one file is too smol to be within threshold,"
        "avoid doing costly sm check"
        if len(self.data) < len(d2) * threshold:
            return False
        elif len(d2) < len(self.data) * threshold:
            return False
        else: 
            return True

    def cmp_to(self, other, threshold=0.8):
        if isinstance(other, FileReport):
            c2 = other.data
        else:
            with open(other) as file2:
                c2 = self.filter_comments_from_py(file2)
        if self.byte_compare(c2, threshold):
            m = sm(None, self.data, c2)
            if m.ratio() >= threshold:
                self.add_result(other, m.ratio())

    def has_matches(self):
        return len(self.similars) > 0
    
    def matches(self):
        return sorted(self.similars, reverse=True)
    

def get_args():
    "invoke argparse, passes to obj in global scope"
    parser = argparse.ArgumentParser(description="checks for submission similarity, plaigiarism",epilog="Copyright 2020 - Eric Brauer")
    parser.add_argument("-p", "--pattern", default='*.py', help="specify wildcard pattern for files to check. Ex: 'a2_*.py'")
    parser.add_argument("-x", "--exclude", default='*check*.py', help="specify wildcard pattern for files to ignore, like check scripts. Ex: 'checkA2.py'")
    parser.add_argument("-t", "--threshold", type=float, default='80', help="When to spawn alert, in percent similarity. Default is 80.")
    parser.add_argument("-b", "--bytes", type=int, help="sets a minimum byte size for comparisons. Use this to filter out assignments with no new code.")
    parser.add_argument("-f", "--target-file", help="when you want to compare all other instances to a target file. Can improve performance.")
    parser.add_argument("-s", "--static", action="store_true", help="Outputs results to standard output, as opposed to a menu for analysis. Menu not yet implemented.")
    parser.add_argument("target_directory", nargs='?', help="directory to find student code")
    args = parser.parse_args() 
    if args.target_directory == None:
        args.target_directory = os.getcwd()
    if not os.path.isdir(args.target_directory):
        print("Please enter a valid file path.")
        sys.exit(1)
    return args

def get_file_list(args):
    "this is an alternate method to get applicable files"
    target_dir = args.target_directory
    pattern = args.pattern
    exclude = args.exclude
    new_list = list()
    for root, dirs, files in os.walk(target_dir):
        for file in files:
            if not fnmatch.fnmatch(file, pattern):
                continue
            elif fnmatch.fnmatch(file, exclude):
                continue
            else:
                path = os.path.join(root, file)
                new_list.append(path)
    return new_list

'''revisit this solution! didn't work, but a better solution'''
def new_ratio(c1: list, c2: list) -> float:
    "compare two files, return a value of % in common"
    total = max(len(c1), len(c2))  # the longest file in number of lines creates total
    c1s = set(c1)
    c2s = set(c2)
    x = 0
    if len(c1s) >= len(c2s):
        largest = c1s
        smallest = c2s
    else:
        largest = c2s
        smallest = c1s
    for line in largest:
        if line in smallest:
            x += 1
    result = x / total
    return result


def strip_nonkw(c1: str) -> str:
    "strips out all var names"
    wordreg = r'\w+'
    lst = findall(wordreg, c1)
    raw = c1
    for word in lst:
        if not iskeyword(word):
            raw = sub(word, '', raw, count=1)
    return raw

def file_contains_errors(file_to_test):
    "second attempt to check for errors"
    print(file_to_test)
    with open(file_to_test) as f:
        source = f.read()
    valid = True
    try:
        ast.parse(source)
    except (SyntaxError, IndentationError):
        valid = False
        traceback.print_exc()  # Remove to silence any errros
    except:
        valid = False
    return valid 

def get_unique_relationships(filename_list):
    "create one new object for each file in our test list"
    new_list = []
    for target in filename_list:
        x = FileReport(target)
        new_list.append(x)
    return new_list

def get_target_relationships(filename_list, target):
    "only one object is created, we are comparing everything to it"
    x = FileReport(target)
    return x


def calculate_scores(file_reports, threshold):
    "inside each object, add files and run comparison"
    for fobj in file_reports:
        for tobj in file_reports:
            if fobj != tobj:
                fobj.cmp_to(tobj, threshold)
    return file_reports

def filter_out_smalls(input, bytes):
    "if a filesize is less than what's specified, remove from set"
    for file in input:
        if os.path.getsize(file) <= bytes:
            input.remove(file)
    return input

if __name__ == '__main__':
    args = get_args()
    threshold = args.threshold
    if 1.0 <= threshold < 100:  # if user gives pcnt in range 0-100
        threshold /= 100  # change to 0.0-1.0
    print(f"Testing with a threshold of {threshold : .1%}.")
    test_list = get_file_list(args)
    if len(test_list) <= 1:
        print('No files to analyze.')
        exit(1)
    errorlist = []  # this will store the files excluded b/c non-zero exit codes
    if args.bytes:
        test_list = filter_out_smalls(test_list, args.bytes)
    print('Files to test: ' + str(len(test_list)))
    if args.target_file:
        uniques = get_target_relationships(test_list, args.target_file)
    else:
        uniques = get_unique_relationships(test_list)
    results = calculate_scores(uniques, threshold)
    results = d.fancy_print_results(results, threshold)
    if not args.static:
        d.call_diff_exec(results)
